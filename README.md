# ğŸ¤– Halo Assistant

Halo is a **personal real-time AI assistant** designed for meetings, coding, and technical discussions.  
It listens, transcribes, understands context, and responds instantly â€” like your own private copilot that runs **locally and offline**.


## âœ¨ Features
- ğŸ™ï¸ **Real-time Speech-to-Text (STT)** with [Whisper](https://github.com/openai/whisper)  
- ğŸ¤– **AI Reasoning** using [Ollama](https://ollama.ai/) with free open-source LLMs (Mistral, LLaMA, Mixtral, etc.)  
- ğŸ—£ï¸ **Text-to-Speech (TTS)** option for spoken replies  
- ğŸ–¥ï¸ **Floating Overlay UI** for quick access (Cluely-style window)  
- ğŸ”Œ **Multiple Modes**  
  - Meeting assistant  
  - Interview prep  
  - Coding assistant  
  - Custom workflows  
- ğŸ“‚ **Automatic transcripts & logs** stored locally  
- âš¡ **GPU acceleration** with NVIDIA CUDA (for fast Whisper + LLM inference)  
- ğŸ”’ 100% **private & offline** (no external API calls required)


## ğŸ“‚ Project Structure
```

halo-assistant/
â”‚â”€â”€ README.md
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ setup.py
â”‚â”€â”€ .env
â”‚â”€â”€ main.py
â”‚
â”œâ”€â”€ configs/          # Settings for models, UI, etc.
â”œâ”€â”€ data/             # Transcripts, logs, cache
â”œâ”€â”€ halo/
â”‚   â”œâ”€â”€ ui/           # Overlay, controls, themes
â”‚   â”œâ”€â”€ core/         # Listener, STT, LLM, TTS, pipeline
â”‚   â”œâ”€â”€ utils/        # Helpers (logging, hotkeys, file utils)
â”‚   â””â”€â”€ modes/        # Meeting, interview, coding modes
â””â”€â”€ tests/            # Unit tests

```

## ğŸ› ï¸ Installation

### 1. Clone Repo
```
git clone https://github.com/<your-username>/halo-assistant.git
cd halo-assistant
````

### 2. Create Conda Env

```
conda create -n halo python=3.10 -y
conda activate halo
```

### 3. Install Dependencies

```
pip install -r requirements.txt
```

### 4. Install Ollama (for LLMs)

Follow instructions here: [Ollama Install](https://ollama.ai/download)

Example: Run **Mistral**

```
ollama run mistral
```

## ğŸš€ Usage

### Run the assistant

```bash
python main.py
```

### Start UI (Streamlit prototype)

```bash
streamlit run halo/ui/overlay.py
```

### Example Workflow

1. Start Halo
2. It listens to your mic and detects when someone speaks
3. Speech â†’ Text (Whisper)
4. Text â†’ Reasoning (Ollama model)
5. AI generates a smart reply
6. (Optional) Reply spoken aloud with TTS


## ğŸ§  Models

* **Speech-to-Text (STT)**

  * Whisper (`tiny`, `base`, `small`, `medium`, `large`)
* **Large Language Models (LLMs)**

  * Free alternatives via **Ollama**:

    * [Mistral](https://mistral.ai)
    * [LLaMA 2](https://ai.meta.com/llama/)
    * [Mixtral](https://mistral.ai/news/mixtral/)
  * Easily switchable in `configs/settings.yaml`

## ğŸ—ºï¸ Roadmap

* [ ] Real-time voice activity detection (VAD)
* [ ] Always-on floating overlay
* [ ] Multi-language transcription
* [ ] Context memory across sessions
* [ ] Desktop app build (PyQt / Electron)



## ğŸ¤ Contributing

Contributions, feature requests, and bug reports are welcome!
Please fork the repo, open an issue, or submit a pull request.

---
Built with â¤ï¸ for personal productivity.

